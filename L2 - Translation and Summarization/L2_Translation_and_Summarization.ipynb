{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translation and Summarization\n",
    "\n",
    "In the example provided, the libraries are already installed. If we wanted to run this, we would have to download the model libraries that we want from Hugging Face & run with the Transformers library.\n",
    "\n",
    "Some use cases and services that can be built using these models are:\n",
    "\n",
    "- Translation Services:\n",
    "    - Document Translation\n",
    "    - Real-Time Translation\n",
    "    - Multilingual Chatbots\n",
    "- Text Sumarization:\n",
    "    - Content Curation\n",
    "    - Information Extraction\n",
    "    - Efficient Reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the `translator` pipeline with Hugging Face Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warning messages\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from transformers import pipeline # Call the pipeline function, invoke model\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about the model used:\n",
    "- No Language Left Behing (NLLB) -  [nllb-200-distilled-600M](https://huggingface.co/facebook/nllb-200-distilled-600M).\n",
    "\n",
    "It has been selected as it is very light and can be run under the 4GB limit offered in DLAI. Before it can be used, one must have downloaded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample translational model\n",
    "translator = pipeline(task=\"translation\",\n",
    "                      model=\"./models/facebook/nllb-200-distilled-600M\",\n",
    "                      torch_dtype=torch.bfloat16) \n",
    "\n",
    "# Define the text to be translated\n",
    "text = \"\"\"\\\n",
    "My puppy is adorable, \\\n",
    "Your kitten is cute.\n",
    "Her panda is friendly.\n",
    "His llama is thoughtful. \\\n",
    "We all have nice pets!\"\"\"\n",
    "\n",
    "# Call the model to translate the text from English to French\n",
    "text_translated = translator(text,\n",
    "                             src_lang=\"eng_Latn\",\n",
    "                             tgt_lang=\"fra_Latn\")\n",
    "text_translated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other languages can be found on the page: [Languages in FLORES-200](https://github.com/facebookresearch/flores/blob/main/flores200/README.md#languages-in-flores-200).\n",
    "\n",
    "For example:\n",
    "-    Afrikaans: afr_Latn\n",
    "-    Chinese: zho_Hans\n",
    "-    Egyptian Arabic: arz_Arab\n",
    "-    French: fra_Latn\n",
    "-    German: deu_Latn\n",
    "-    Greek: ell_Grek\n",
    "-    Hindi: hin_Deva\n",
    "-    Indonesian: ind_Latn\n",
    "-    Italian: ita_Latn\n",
    "-    Japanese: jpn_Jpan\n",
    "-    Korean: kor_Hang\n",
    "-    Persian: pes_Arab\n",
    "-    Portuguese: por_Latn\n",
    "-    Russian: rus_Cyrl\n",
    "-    Spanish: spa_Latn\n",
    "-    Swahili: swh_Latn\n",
    "-    Thai: tha_Thai\n",
    "-    Turkish: tur_Latn\n",
    "-    Vietnamese: vie_Latn\n",
    "-    Zulu: zul_Latn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Free up some memory before continuing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc       # Garbage collection module\n",
    "del translator  # Delete the model\n",
    "gc.collect()    # Clean up the memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the `summarization` pipeline with Hugging Face Transformers Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about the model used: [bart-large-cnn](https://huggingface.co/facebook/bart-large-cnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the summarization model\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=\"./models/facebook/bart-large-cnn\",\n",
    "                      torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the text to be summarized\n",
    "text = \"\"\"Paris is the capital and most populous city of France, with\n",
    "          an estimated population of 2,175,601 residents as of 2018,\n",
    "          in an area of more than 105 square kilometres (41 square\n",
    "          miles). The City of Paris is the centre and seat of\n",
    "          government of the region and province of ÃŽle-de-France, or\n",
    "          Paris Region, which has an estimated population of\n",
    "          12,174,880, or about 18 percent of the population of France\n",
    "          as of 2017.\"\"\"\n",
    "\n",
    "# Recieve the summarized text\n",
    "summary = summarizer(text,\n",
    "                     min_length=10,\n",
    "                     max_length=100)\n",
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
