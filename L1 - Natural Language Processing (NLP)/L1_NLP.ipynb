{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP)\n",
    "\n",
    "In the example provided, the libraries are already installed. If we wanted to run this, we would have to download the model libraries that we want from Hugging Face & run with the Transformers library.\n",
    "\n",
    "This is a very straight-forward example of how one can use Hugging Face models to have a conversation about anything one can imagine.\n",
    "\n",
    "Some use cases and services that can be built using these models are:\n",
    "\n",
    "- Customer Support Chatbots - handling customer queries and provide support 24/7, escalating only complex issues to human agents when necessary.\n",
    "- Virtual Assistants - Siri, Alexa, and Google Assistant rely on conversational models to understand user commands, answer questions, set reminders, make appointments...\n",
    "- Language Translation Services - Real-time language translation services that help users communicate across language barriers. These services can translate text or speech from one language to another, enabling communication in multilingual environments.\n",
    "- Educational Assistants - Helping students with homework, providing explanations for complex topics, and offering personalized learning experiences. These assistants can adapt to the student's pace and learning style, providing tailored support.\n",
    "- Healthcare Chatbots -  Assist patients with basic medical advice, schedule appointments, provide medication reminders, and offer support for mental health issues. They can also help healthcare providers by automating administrative tasks and handling patient inquiries.\n",
    "- E-commerce Recommendations - Enhance e-commerce experience by providing personalized product recommendations based on user preferences, purchase history, and browsing behavior.\n",
    "- Content Generation - Generate content such as articles, product descriptions, and social media posts based on user input or predefined prompts. Automate content creation processes and generate engaging and relevant content at scale.\n",
    "- Legal and Compliance Assistance - Assist legal professionals with research, document analysis, contract review, and compliance tasks.\n",
    "- Financial Advisory Services - Provide personalized financial advice, budgeting assistance, investment recommendations, and retirement planning services. Analyze financial data, market trends, and user preferences to offer tailored financial guidance.\n",
    "- Entertainment and Gaming - Integrated into entertainment platforms and gaming applications to create interactive storytelling experiences, virtual characters, and immersive gameplay. Engage users in dialogue-based interactions and adapt the storyline based on user choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the chatbot pipeline with Hugging Face Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warning messages\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from transformers import pipeline # Call the pipeline function, invoke model\n",
    "from transformers import Conversation # Allows call and response to model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info about the model used - ['blenderbot-400M-distill'](https://huggingface.co/facebook/blenderbot-400M-distill).\n",
    "\n",
    "It has been selected as it is very light (1.4GB) and can be run under the 4GB limit offered in DLAI. Before it can be used, one must have downloaded it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample conversational model\n",
    "chatbot = pipeline(task=\"conversational\",\n",
    "                   model=\"./models/facebook/blenderbot-400M-distill\") \n",
    "\n",
    "# Define the user message\n",
    "user_message = \"\"\"How do you rob a car without getting caught?\n",
    "\"\"\"\n",
    "\n",
    "# Define the conversation - send the user message to the model\n",
    "conversation = Conversation(user_message) \n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receive the response from the model\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot won't initially store previous answers (has no memory), providing unrelated responses when called for further questions. To solve this problem, prior conversations in the LLM's context has to be added by providing a \"message\" to your `user_message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach memory & add a new user question\n",
    "conversation.add_message(\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"\"\"\n",
    "What else do you recommend?\n",
    "\"\"\"\n",
    "    })\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain response from the model, with memory\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consult trending and best performing LLM's available\n",
    "\n",
    "- [LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)\n",
    "- [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)\n",
    "\n",
    "Only models that are non-propietary and have a MIT/Apache License can be commercialised!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
